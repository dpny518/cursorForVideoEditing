[
  {
    "model_id": "gemma-2b-it-q4f16_1-MLC",
    "quantization": "gemma-2b-it-q4f16_1",
    "link": "https://huggingface.co/mlc-ai/gemma-2b-it-q4f16_1-MLC"
  },
  {
    "model_id": "gemma-2b-it-q4f32_1-MLC",
    "quantization": "gemma-2b-it-q4f32_1",
    "link": "https://huggingface.co/mlc-ai/gemma-2b-it-q4f32_1-MLC"
  },
  {
    "model_id": "Phi-3-mini-4k-instruct-q4f16_1-MLC",
    "quantization": "Phi-3-mini-4k-instruct-q4f16_1",
    "link": "https://huggingface.co/mlc-ai/Phi-3-mini-4k-instruct-q4f16_1-MLC"
  },
  {
    "model_id": "Phi-3-mini-4k-instruct-q4f32_1-MLC",
    "quantization": "Phi-3-mini-4k-instruct-q4f32_1",
    "link": "https://huggingface.co/mlc-ai/Phi-3-mini-4k-instruct-q4f32_1-MLC"
  },
  {
    "model_id": "Llama-3-8B-Instruct-q4f16_1-MLC",
    "quantization": "Llama-3-8B-Instruct-q4f16_1",
    "link": "https://huggingface.co/mlc-ai/Llama-3-8B-Instruct-q4f16_1-MLC"
  },
  {
    "model_id": "Llama-3-8B-Instruct-q4f32_1-MLC",
    "quantization": "Llama-3-8B-Instruct-q4f32_1",
    "link": "https://huggingface.co/mlc-ai/Llama-3-8B-Instruct-q4f32_1-MLC"
  }
]
